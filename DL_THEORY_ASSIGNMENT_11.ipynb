{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aead529b",
   "metadata": {},
   "source": [
    "### 1. Write the Python code to implement a single neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs, learning_rate=0.1):\n",
    "        self.weights = np.random.rand(num_inputs)\n",
    "        self.bias = np.random.rand()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def activate(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        summation = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.activate(summation)\n",
    "\n",
    "    def train(self, inputs, target):\n",
    "        prediction = self.predict(inputs)\n",
    "        error = target - prediction\n",
    "        self.weights += self.learning_rate * error * inputs\n",
    "        self.bias += self.learning_rate * error\n",
    "\n",
    "# Example usage\n",
    "# Assuming 2 inputs (features) for simplicity\n",
    "inputs = np.array([1, 0])  # Example input\n",
    "target = 1  # Example target (output)\n",
    "\n",
    "perceptron = Perceptron(num_inputs=2, learning_rate=0.1)\n",
    "perceptron.train(inputs, target)\n",
    "\n",
    "# Predict using the trained perceptron\n",
    "prediction = perceptron.predict(inputs)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc24c6e",
   "metadata": {},
   "source": [
    "### 2. Write the Python code to implement ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# Example usage\n",
    "x = np.array([-2, -1, 0, 1, 2])\n",
    "print(\"Input:\", x)\n",
    "print(\"ReLU Output:\", relu(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f227ba",
   "metadata": {},
   "source": [
    "### 3. Write the Python code for a dense layer in terms of matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bcd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = np.dot(inputs, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "# Example usage\n",
    "# Assuming input size of 3 and output size of 2 for simplicity\n",
    "input_size = 3\n",
    "output_size = 2\n",
    "inputs = np.array([1.0, 2.0, 3.0])  # Example input\n",
    "\n",
    "dense_layer = DenseLayer(input_size, output_size)\n",
    "output = dense_layer.forward(inputs)\n",
    "\n",
    "print(\"Output after dense layer:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde6354b",
   "metadata": {},
   "source": [
    "### 4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions and functionality built into Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(input_size)]\n",
    "        self.bias = [random.uniform(-1, 1) for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = [sum(w * inp for w, inp in zip(weight, inputs)) + bias for weight, bias in zip(self.weights, self.bias)]\n",
    "        return self.output\n",
    "\n",
    "# Example usage\n",
    "# Assuming input size of 3 and output size of 2 for simplicity\n",
    "input_size = 3\n",
    "output_size = 2\n",
    "inputs = [1.0, 2.0, 3.0]  # Example input\n",
    "\n",
    "dense_layer = DenseLayer(input_size, output_size)\n",
    "output = dense_layer.forward(inputs)\n",
    "\n",
    "print(\"Output after dense layer:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97684e",
   "metadata": {},
   "source": [
    "### 5. What is the “hidden size” of a layer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a960f33",
   "metadata": {},
   "source": [
    "The \"hidden size\" of a layer refers to the number of neurons or units in that layer. It represents the dimensionality of the layer's output or activations before passing through any activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c4329",
   "metadata": {},
   "source": [
    "### 6. What does the t method do in PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defeda89",
   "metadata": {},
   "source": [
    "The `.t()` method in PyTorch performs the transpose operation on a tensor, swapping its dimensions. For a 2D tensor, it swaps rows and columns, effectively transposing the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b8f33",
   "metadata": {},
   "source": [
    "### 7. Why is matrix multiplication written in plain Python very slow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9650b503",
   "metadata": {},
   "source": [
    "Matrix multiplication written in plain Python is slow due to the lack of optimized operations available in libraries like NumPy. Plain Python loops are inherently slow for numerical operations, and they don't leverage highly optimized, low-level linear algebra libraries that are used in optimized frameworks. Libraries like NumPy utilize highly efficient C or Fortran backends for matrix operations, significantly speeding up computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c23d7",
   "metadata": {},
   "source": [
    "### 8. In matmul, why is ac==br?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac2131",
   "metadata": {},
   "source": [
    "In matrix multiplication (matmul), the condition \"ac == br\" ensures that the two matrices being multiplied can be legally multiplied. Specifically, for matrix multiplication of A (shape: a x c) and B (shape: b x r) to be valid, the number of columns in A (c) must be equal to the number of rows in B (b), hence \"ac == br\". This condition is essential for a valid matrix multiplication operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b08062",
   "metadata": {},
   "source": [
    "### 9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd10b6a",
   "metadata": {},
   "source": [
    "In Jupyter Notebook, you can measure the time taken for a single cell to execute using the `%%time` or `%%timeit` magic commands.\n",
    "\n",
    "1. **Using `%%time`**:\n",
    "   - Place `%%time` at the beginning of the cell you want to measure.\n",
    "   - Run the cell, and it will display the time taken for the cell to execute.\n",
    "\n",
    "    ```python\n",
    "    %%time\n",
    "\n",
    "    # Your code here\n",
    "    ```\n",
    "\n",
    "2. **Using `%%timeit`**:\n",
    "   - Place `%%timeit` at the beginning of the cell you want to measure.\n",
    "   - Run the cell, and it will execute the code multiple times to get an average and standard deviation of the execution time.\n",
    "\n",
    "    ```python\n",
    "    %%timeit\n",
    "\n",
    "    # Your code here\n",
    "    ```\n",
    "\n",
    "Choose the appropriate method based on whether you want a single measurement (`%%time`) or multiple measurements with an average and standard deviation (`%%timeit`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64d060",
   "metadata": {},
   "source": [
    "### 10. What is elementwise arithmetic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6372e",
   "metadata": {},
   "source": [
    "Elementwise arithmetic refers to performing arithmetic operations (addition, subtraction, multiplication, division) between corresponding elements of two arrays or tensors. Each element in one array is operated upon independently with the corresponding element in the other array, resulting in a new array with the same shape as the original arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adf200",
   "metadata": {},
   "source": [
    "### 11. Write the PyTorch code to test whether every element of a is greater than the corresponding element of b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([0, 1, 2])\n",
    "\n",
    "result = (a > b).all()\n",
    "print(\"Are all elements of 'a' greater than the corresponding elements of 'b'?\", result.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d132de",
   "metadata": {},
   "source": [
    "### 12. What is a rank-0 tensor? How do you convert it to a plain Python data type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A rank-0 tensor, also known as a scalar, is a tensor with zero dimensions. It represents a single value. \n",
    "### To convert a rank-0 tensor (scalar) to a plain Python data type, you can use the `.item()` method in PyTorch.\n",
    "\n",
    "### Example:\n",
    "import torch\n",
    "\n",
    "scalar_tensor = torch.tensor(42)  # Rank-0 tensor (scalar)\n",
    "plain_python_value = scalar_tensor.item()  # Convert to a plain Python data type\n",
    "\n",
    "print(\"Scalar as a tensor:\", scalar_tensor)\n",
    "print(\"Scalar as a plain Python data type:\", plain_python_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b75a4",
   "metadata": {},
   "source": [
    "### 13. How does elementwise arithmetic help us speed up matmul?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ae340",
   "metadata": {},
   "source": [
    "Elementwise arithmetic doesn't directly speed up matrix multiplication (`matmul`), but it's a fundamental step in many matrix operations. In the context of matrix multiplication:\n",
    "\n",
    "1. **Intermediate Computations**: Elementwise arithmetic is often involved in intermediate computations within the matrix multiplication algorithm.\n",
    "\n",
    "2. **Parallelization**: The operations involved in elementwise arithmetic can be parallelized efficiently, leading to potential speedup in the overall computation, including matrix multiplication.\n",
    "\n",
    "3. **Optimized Implementations**: High-performance libraries like BLAS (Basic Linear Algebra Subprograms) and optimized frameworks use efficient implementations of elementwise operations, which indirectly contribute to the speed of matrix multiplication.\n",
    "\n",
    "In summary, although elementwise arithmetic itself doesn't directly speed up matrix multiplication, it plays a critical role in efficient implementations and optimizations that can lead to faster overall computations, including matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a11dd",
   "metadata": {},
   "source": [
    "### 14. What are the broadcasting rules?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f166809",
   "metadata": {},
   "source": [
    "Broadcasting rules in NumPy (and similar frameworks) allow for arithmetic operations on arrays of different shapes, making computations possible even if dimensions don't match. In very short:\n",
    "\n",
    "1. **Dimensions Compatibility**: Arrays must have either the same dimensions or one of them must have dimension 1.\n",
    "\n",
    "2. **Expand Dimensions**: Dimensions of size 1 are \"broadcasted\" to match the corresponding dimension of the other array.\n",
    "\n",
    "3. **Operation Execution**: The operation is executed elementwise after broadcasting, treating dimensions of size 1 as if they were the size of the larger array.\n",
    "\n",
    "Broadcasting enables efficient elementwise operations without explicitly replicating arrays, enhancing computational flexibility and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4457cfa",
   "metadata": {},
   "source": [
    "### 15. What is expand_as? Show an example of how it can be used to match the results of broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe64a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create tensors with different shapes\n",
    "a = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "b = torch.tensor([10, 20, 30])     # Shape: (3,)\n",
    "\n",
    "# Using broadcasting\n",
    "result_broadcasting = a * b  # Broadcasting\n",
    "\n",
    "# Using expand_as\n",
    "b_expanded = b.unsqueeze(1).expand_as(a)  # Expanding dimensions to match 'a'\n",
    "result_expand_as = a * b_expanded  # Elementwise multiplication\n",
    "\n",
    "print(\"Result using broadcasting:\\n\", result_broadcasting)\n",
    "print(\"Result using expand_as:\\n\", result_expand_as)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
